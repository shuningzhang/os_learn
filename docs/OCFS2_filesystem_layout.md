## 概述
前文已经大概介绍过OCFS2的[部署和应用场景](http://www.itworld123.com/2018/11/17/ocfs2%e9%9b%86%e7%be%a4%e6%96%87%e4%bb%b6%e7%b3%bb%e7%bb%9f%e5%8f%8a%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba/)，本文及后续文章重点介绍OCFS2文件系统的具体实现。为了便于后续代码的理解，本文首先介绍一下该文件系统关键数据的磁盘布局情况。理解磁盘布局是理解OCFS2文件系统的基础，只有理解了布局，才能更好的理解代码中的各种处理流程。

> 本文介绍基于Linux4.1.12内核，其它版本内核可能稍有不同，但不影响理解。
> 本文示例文件系统格式化采用默认参数，也即4K逻辑块大小和128K簇块大小

本文首先介绍文件系统在`整个磁盘的布局`情况，然后介绍`文件夹内数据`和`文件内数据`的布局。整体原则是从整体到局部，从轮廓到细节的顺序。
## 整体磁盘布局
如下图OCFS2文件系统与Ext4文件系统类似，将磁盘划分为若干组，Ext4文件系统叫块组（block group），这里成为簇组（cluster group），虽然概念不同，但大体用途基本一致。如果不了解Ext4文件系统也没有关系，下图能很清楚的说明磁盘的整体布局情况。如图所示最上面方框（第一行方框）表示的是簇组（cluster group），分别是Cluster Group0、Cluster Group1等等。

![磁盘布局总图](http://github.itworld123.com/linux/fs/ocfs2_disk_layout.png)

如上图所示除了第一个簇组（Cluster Group0）比较特殊之外，其它簇组都是一样的，也就是最前面一个块是簇组描述信息，其后数据簇，也就是被管理的单元。第一个簇组特殊的原因是其中包含了很多元数据（管理数据），包括文件系统的超级块、系统文件夹和系统文件等内容。

> OCFS2在管理磁盘空间时同时采用两种管理单元，一种叫做逻辑块，大小范围从512B到4K，大小必需是512B的2的幂整数倍（也即512B、1K等以此类推）；另外一种叫簇组，大小范围是4KB到1MB，大小必需是4KB的2的幂整数倍。

如图第二行所示，

本地分配
簇大小与簇组及本地分配大小间的关系。以128K簇为例，此时簇组的大小是4032M，本地分配可以管理的最大空间是3888M。关于簇组的最大管理空间，由于簇组通过一个块（4K）的组描述符进行管理，而该描述符前面基本描述信息占了64B，因此位图剩余的可用空间为4032(4096-64)，因此最大32256个簇，也即4032M（32256*128KB）。对于本地分配的最大管理空间，由于使用的ocfs2_dinode进行管理，也是占用1个块（4K），前面描述信息占用了208B，因此剩余的空间可以管理的最大空间为3888M。？？？

| cluster size | group size | local alloc |
|--------------|------------|-------------|
|4K   | 126M   | 121M                |
|8K   |252M    | 243M   |
|16K  | 504M   |   486M|
|32K  | 1008M  | 972M|
|64K  | 2016M  | 1944M|
|128K | 4032M  |  3888M|
|256K |  8064M |  7776M|
|512K | 16128M |  15552M|
|1024K| 32256M |  31104M|

## 文件夹数据
文件夹中数据的存储有两种模式，如果开启了inline-data特性，那么起始情况下这些数据（文件名称和inode等信息）是存放在文件夹的inode的所在的区域内的。由于一个inode默认情况下占用4K的空间，因此对于文件数量不太多的文件夹，通过这块区域就可以存储，不需要额外申请空间。如果在文件夹中有海量文件的情况下，inode节点空间不足以存储这些信息，此时就会通过extent的方式存储这些数据。另外，为了便于文件夹内文件的检索，OCFS2有实现了一个索引树，可以通过该索引树快速检索文件。

### inline模式


### extent模式

## 文件内数据

### inline模式

### extent模式
